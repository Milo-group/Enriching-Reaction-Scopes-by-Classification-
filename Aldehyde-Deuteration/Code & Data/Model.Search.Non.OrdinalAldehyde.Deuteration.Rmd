---
title: "Aldehyde Deuteration - Model Search"
output:
  word_document:
    highlight: null
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE,
                      comment = NA,
                      message = FALSE,
                      warning = FALSE,
                      results = 'asis',
                      error = TRUE,
                      fig.height = 8)

# The following packages are installed and loaded 
library(data.table)
library(tidyr)
library(ggplot2)
library(ggrepel)
library(scales)
library(reshape2)
library(tibble)
library(caret)
library(plyr)
library(dplyr)
library(default)
glm.control(maxit = 100)

default(data.frame) <- list(check.names = FALSE)
```

```{r Functions and Data,echo=TRUE, include=FALSE}
# k.fold.ordinal.log description:
# 
# Takes a formula, dataset, number of folds and the output vector. 
# Uses nnet::multinom (see nnet v7.3-14 documentation - multinom).
# Divides data into folds, each time using a single fold as the test set
# and the rest as training. 
# Creates a predicted probalities and classes dataframe for each run 
# which is then combined to form a complete table.
# Returns a classifictaion table for predicted outcome vs. experimental observations,
# an accuracy measure based on that table and the probabilities table. 
stratified <- function(df, group, size) {
  df.interaction <- interaction(df[group], drop = TRUE)
  df.table <- table(df.interaction)
  df.split <- split(df, df.interaction)
  if (length(size) > 1) {
    if (length(size) != length(df.split))
      stop("Number of groups is ", length(df.split),
           " but number of sizes supplied is ", length(size))
    if (is.null(names(size))) {
      n <- setNames(size, names(df.split))
    } else {
      ifelse(all(names(size) %in% names(df.split)),
             n <- size[names(df.split)],
             stop("Named vector supplied with names ",
                  paste(names(size), collapse = ", "),
                  "\n but the names for the group levels are ",
                  paste(names(df.split), collapse = ", ")))
    }
  } else if (size < 1) {
    n <- round(df.table * size, digits = 0)
  } else if (size >= 1) {
    if (all(df.table >= size) || isTRUE(replace)) {
      n <- setNames(rep(size, length.out = length(df.split)),
                    names(df.split))
    } else {
      message(
        "Some groups\n---",
        paste(names(df.table[df.table < size]), collapse = ", "),
        "---\ncontain fewer observations",
        " than desired number of samples.\n",
        "All observations have been returned from those groups.")
      n <- c(sapply(df.table[df.table >= size], function(x) x = size),
             df.table[df.table < size])
    }
  }
  temp <- lapply(
    names(df.split),
    function(x) df.split[[x]][sample(df.table[x],
                                     n[x], replace = F), ])
  set1 <- do.call("rbind", temp)
  set1
}

k.fold.ordinal.log <- function(formula, data, folds = NULL,
                               outcome.column = which(colnames(data) == 'class'),
                               stratify = F,
                               sample.vector = floor(round(summary(data$class)/min(summary(data$class))))) {
  models <- list()
  probalities <- list()
  acc <- list()
  class.pred <- list()
  if (stratify == T && !is.null(sample.vector) && is.null(folds)) {
    sets <- list()
    for (i in 1:ceiling(dim(data)[1] / sum(sample.vector))) {
      if (length(sets) == 0) {
        pool.data <- data
      } else {
        pool.data <- dplyr::setdiff(data, do.call(rbind, sets))
      }
      if (dim(pool.data)[1] < sum(sample.vector) & dim(pool.data)[1] > 0) {
        sets[[i]] <- pool.data
        pool.data <- data.frame()
      }
      if (nrow(pool.data) > 0 & any(summary(pool.data$class) < sample.vector)) {
        for (j in 1:nrow(pool.data)) {
          ifelse (j <= length(sets), sets[[j]] <- rbind(sets[[j]], pool.data[j, ]),
                  sets[[(j - length(sets))]] <- rbind(sets[[(j - length(sets))]], pool.data[j, ]))
        }
        is_empty <- function(x) (nrow(x) == 0 || is.null(x))
        sets <- sets[sapply(sets, is_empty) == FALSE]
      } else {
        if (nrow(pool.data) > 0) suppressWarnings(sets[[i]] <- stratified(pool.data, 'class', sample.vector))
      }
      if (i == ceiling(dim(data)[1] / sum(sample.vector))) {
        check <- dim(do.call(rbind, sets)) == dim(data)
        if (!all(check)) {
          print("Wasn't able to stritify as wanted. Check with another sample vector.")
        }
      }
    }
    for (i in 1:length(sets)) {
      sets[[i]] <- dplyr::mutate(sets[[i]], split.assign = i)
    }
    new_dat <- do.call(rbind, sets)
    new_dat <- dplyr::arrange(new_dat, flag)
    for (i in 1:length(sort(unique(new_dat$split.assign)))) {
      train <- new_dat[new_dat$split.assign != i,]
      test <- new_dat[new_dat$split.assign == i,]
      num.of.vars <- stringi::stri_count(formula, fixed = '+')
      start <- c(rep(0, (num.of.vars + 2)), 1)
      models[[match(i,sort(unique(new_dat$split.assign)))]] <- MASS::polr(formula,
                                                                          data = train,
                                                                          Hess = T, start = start,
                                                                          control = list(maxit = 1000))
      probalities[[match(i,sort(unique(new_dat$split.assign)))]] <- data.frame(predict(models[[match(i,sort(unique(new_dat$split.assign)))]], 
                                                                                       newdata = test,
                                                                                       "probs")*100)
      class.pred[[match(i,sort(unique(new_dat$split.assign)))]] <- data.frame(predict(models[[match(i,sort(unique(new_dat$split.assign)))]],
                                                                                      newdata = test,
                                                                                      "class"))
      probalities[[match(i,sort(unique(new_dat$split.assign)))]] <- cbind(probalities[[match(i,sort(unique(new_dat$split.assign)))]],
                                                                          class.pred[[match(i,sort(unique(new_dat$split.assign)))]],
                                                                          test$flag)
      names(probalities[[match(i,sort(unique(new_dat$split.assign)))]]) <- c('cond1','cond2','cond3', 'prediction','flag')
    }
  } else {
    if (folds == nrow(data)) {
      split.assign <- sample(1:folds, nrow(data), replace = F)
    } else {
      split.assign <- caret::createFolds(1:dim(data)[1], folds, list = F)
    }
    new_dat <- cbind(data, split.assign)
    for (i in 1:folds) {
      train <- new_dat[split.assign != i,]
      test <- new_dat[split.assign == i,]
      num.of.vars <- stringi::stri_count(formula, fixed = '+')
      start <- c(rep(0, (num.of.vars + 2)), 1)
      models[[match(i,1:folds)]] <- MASS::polr(formula,
                                               data = train,
                                               Hess = T, start = start,
                                               control = list(maxit = 1000))
      if (folds == nrow(data)) {
        probalities[[match(i,1:folds)]] <- data.table::transpose(data.frame(predict(models[[match(i,1:folds)]], 
                                                                                    newdata = test, "probs")*100))
      } else {
        probalities[[match(i,1:folds)]] <- data.frame(predict(models[[match(i,1:folds)]], 
                                                              newdata = test, "probs")*100)
      }
      class.pred[[match(i,1:folds)]] <- data.frame(predict(models[[match(i,1:folds)]], newdata = test, "class"))
      probalities[[match(i,1:folds)]] <- cbind(probalities[[match(i,1:folds)]],class.pred[[match(i,1:folds)]],test$flag)
      names(probalities[[match(i,1:folds)]]) <- c('cond1','cond2','cond3', 'prediction','flag')
    }
  }
  
  probs <- data.frame(do.call(rbind, probalities))
  probs <- probs[order(probs$flag),]
  probs[,1:3] <- round(probs[,1:3],digits = 0)
  pred <- probs[,4]
  pred <- plyr::mapvalues(pred, 
                          from=c("1","2","3"), 
                          to=c("A","B",'C'))
  actual <- data[[outcome.column]]
  actual <- plyr::mapvalues(actual, 
                            from=c("1","2","3"), 
                            to=c("A","B",'C'))
  ct <- table(actual, pred)
  acc <- round((sum(diag(ct))/sum(ct))*100,2)
  ct.df <- data.frame(ct)
  TP <- ct.df$Freq[ct.df$actual == ct.df$pred]
  TP_FN <- list()
  TN <- list()
  TN_FP <- list()
  J <- list()
  for (i in levels(ct.df$actual)) {
    TP_FN[[i]] <- ct.df$Freq[ct.df$actual == i]
    TP_FN[[i]] <- sum(TP_FN[[i]])
    TP_FN[[i]] <- TP[which(levels(ct.df$actual) == i)]/TP_FN[[i]]
    TN[[i]] <- sum(ct.df$Freq[dplyr::intersect(which(ct.df$pred != i),
                                               which(ct.df$actual != i))])
    TN_FP[[i]] <- sum(ct.df$Freq[(ct.df$actual != i)])
    TN_FP[[i]] <- TN[[i]]/TN_FP[[i]]
    J[[i]] <- TP_FN[[i]] + TN_FP[[i]] - 1
  }
  J.small <- J[which.min(summary(data$class))]
  return(list(acc, J.small, ct, probs))
}

sub_model_log_McFadden <- function(data, out.col = which(colnames(data) == 'class'),
                                   min = 4, max = floor(dim(data)[1]/5)) {
  output <- stringr::str_c('`',names(data[out.col]),'`')
  vars <- names(data[,-out.col])
  vars <- vars[vars != 'flag']
  for (i in 1:length(vars)) {
    vars[i] <- stringr::str_c('`',vars[i],'`')
  }
  comb.list <- list()
  R2.list <- list()
  for (i in min:max) {
    comb.list[[i]] <- data.frame(aperm(combn(vars,i)),stringsAsFactors = F)
    comb.list[[i]][,dim(comb.list[[i]])[2]+1] <- do.call(paste, 
                                                         c(comb.list[[i]][names(comb.list[[i]])],
                                                           sep=" + "))
    names(comb.list[[i]])[dim(comb.list[[i]])[2]] <- 'formula'
    for (co in names(comb.list[[i]])[1:length(names(comb.list[[i]]))-1]) comb.list[[i]][co] <- NULL
  }
  comb.list <- plyr::compact(comb.list)
  forms <- do.call(rbind,comb.list)
  names(forms) <- 'formula'
  for (i in 1:dim(forms)[1]) {
    forms$formula[i] <- stringr::str_c(output,' ~ ',forms$formula[i])
    test.1 <- nnet::multinom(forms$formula[i],
                             data = data,
                             maxit = 2000, trace = F)
    test.0 <- nnet::multinom(class ~ 1,data = data, maxit = 2000, trace=F)
    loglik.0 <- as.numeric(nnet:::logLik.multinom(test.0))
    loglik.1 <- as.numeric(nnet:::logLik.multinom(test.1))
    R2.list[i] <- round((1 - (loglik.1/loglik.0)),digits = 3)
  }
  forms[,2] <- do.call(rbind,R2.list)
  names(forms)[2] <- 'McFadden R2'
  out.models <- head(dplyr::arrange(forms,desc(forms[,2])),10)
  return(out.models)
}


# kf.iter.ordinal.ordinal description:
# 
# Takes a formula, dataset, number of folds and the output vector along with 
# number of iterations. 
# Runs k.fold.ordinal.log by iterations numbers and returns the average 
# accuracy over all iterations, the best and worst accuracy and 
# best and worst classification tables.

kf.iter.ordinal <- function(formula, data, folds = NULL, out.col=which(colnames(data) == 'class'),
                    stratify = F,
                    sample.vector = floor(round(summary(data$class)/min(summary(data$class)))),
                    iterations, verbose = F) {
  iter.list <- list()
  ct.list <- list()
  for (i in 1:iterations) {
    mod <- k.fold.ordinal.log(formula, data, folds, out.col, stratify, sample.vector)
    iter.list[[match(i,1:iterations)]] <- mod[[1]]
    ct.list[[match(i,1:iterations)]] <- mod[[3]]
  }
  over.all.accuracy <- round(Reduce(`+`,iter.list)/iterations,digits = 2)
  best <- iter.list[which.max(iter.list)]
  worst <- iter.list[which.min(iter.list)]
  Accuracies.tab <- cbind(over.all.accuracy, best, worst)
  colnames(Accuracies.tab) <- c("Avergae Accuracy", "Best", "Worst")
  Accuracies <- knitr::kable(Accuracies.tab,
                             caption = "\n\nCross Validation Accuracies - Avergare(left), Best (middle) and Worst (True)")
  tab <- suppressMessages(cbind(dcast(data.frame(ct.list[which.max(iter.list)]),actual~pred),
                                rep("***",3),
                                dcast(data.frame(ct.list[which.min(iter.list)]),actual~pred)))
  names(tab)[5] <- ""
  cts <- knitr::kable(tab,
                      caption = "\n\nCross Validation Results - Best (left) and Worst (True) Classification Tables")
  if (!is.null(folds)) {
    Headline.caption <- "\n\n Leave One Out Cross Validation"
  }
  if (stratify == T) {
   Headline.caption <- paste("\n\nStratified (# of samples in the smallest group) Folds Cross Validation - ",
                             iterations,
                             "Iterations")  
  }
  dummy.df <- data.frame(NULL)
  Headline <- knitr::kable(dummy.df, caption = Headline.caption, )
  if (verbose == T) {
    print(Headline)
    print(cts)
    print(Accuracies)
  }
  invisible(over.all.accuracy)
}


# mod.info.ordinal description:
# 
# Takes a nnet::multinom model object.
# using the full data set as both training and testing sets, model information is extracted.
# Creates a class.table object to be used in confusion matrix plotting,
# computes and returnes varibale importance as the sum of each coefficient's absolute value
# over all predictied classes (See caret v6.0-86 documentation - varImp),
# accuracy based on classification table, 
# coeffcient's exponent as another measure of importance 
# and McFadden's pseudo R squared for multinomial logistic regression (T. Domencich and D. L. McFadden, 1975).

mod.info <- function(model, data, verbose = T, save.acc = F) {
  pred <- predict(test,newdata = data, 'class')
  pred <- plyr::mapvalues(pred, 
                    from=c("1","2","3"), 
                    to=c("A","B","C"), warn_missing = F)
  actual <- data$class
  actual <- plyr::mapvalues(actual, 
                      from=c("1","2","3"), 
                      to=c("A","B","C"), warn_missing = F)
  example <- tibble(actual, pred)
  all_vec <- as.factor(LETTERS[1:3])
  example[] <- lapply(example, factor, levels = all_vec)
  
  class.table <<- table(example)
  if (save.acc == T) Acc.print <<- round((sum(diag(class.table))/sum(class.table))*100,2)
  Accuracy <- paste(round((sum(diag(class.table))/sum(class.table))*100,2),"%",sep = '')
  test.0 <- nnet::multinom(class ~ 1,data = data, maxit = 2000, trace=F)
  test.1 <- test
  
  loglik.0 <- as.numeric(nnet:::logLik.multinom(test.0))
  loglik.1 <- as.numeric(nnet:::logLik.multinom(test.1))
  
  McFadden_R2 <- round((1 - (loglik.1/loglik.0)),digits = 3)
  st <- cbind(Accuracy,McFadden_R2)
  names(st) <- c("Accuracy", "McFadden_R2")
  stats <- knitr::kable(st, 
                        caption = "\n\nFull Model Stats - Overall Accuracy and Pseudo-R2")
  ce <- knitr::kable(coef(test),caption = "\n\nModel Coefficients")
  if (verbose == T) {
    print(stats)

    print(ce)
  }
}


# ct.plot description:
# 
# Takes a class table and computes;
# * Recall - TP/(TP+FN) & complimentary percentages of False prdicitions in each cell.
# * Precision - TP/(TP+FP) for each prediction class.
# * Accuracy - all.TP/total.
# Classifies into True and False predictions and presents class size.

ct.plot <- function(class.table, plot.title, conformation) {
  ct <- as.matrix(class.table)
  total <- rep(NA, nrow(ct))
  ct <- cbind(ct,total)
  for (i in 1:dim(ct)[1]) {
    ct[i,4] <- sum(ct[i,1:3])
  }
  total <- rep(NA, ncol(ct))
  ct <- rbind(ct,total)
  for (i in 1:dim(ct)[2]) {
    ct[dim(ct)[1],i] <- sum(ct[1:(dim(ct)[1] - 1),i])
  }
  ct <- melt(ct)
  names(ct) <- c('Exp','Pred','Freq')
  ct$Exp <- as.character(ct$Exp)
  ct$Pred <- as.character(ct$Pred)
  
  ct <- dplyr::mutate(ct, Legend=rep(NA, nrow(ct)))
  ct <- dplyr::mutate(ct,Proportions = rep(NA, nrow(ct)))
  
  
  
  for (i in as.numeric(row.names(ct[ct$Exp!='total' & ct$Pred!='total', ]))) {
    if (ct$Exp[[i]]=='A') {
      ct$Proportions[[i]] <- ct$Freq[[i]]/sum(ct$Freq[ct$Exp=='A' & ct$Pred!='total'])
    }
    if (ct$Exp[[i]]=='B') {
      ct$Proportions[[i]] <- ct$Freq[[i]]/sum(ct$Freq[ct$Exp=='B' & ct$Pred!='total'])
    }
    if (ct$Exp[[i]]=='C') {
      ct$Proportions[[i]] <- ct$Freq[[i]]/sum(ct$Freq[ct$Exp=='C' & ct$Pred!='total'])
    }
    if (ct$Exp[i] == ct$Pred[i]) {
      ct$Legend[i] <- 'True'
    } else {
      ct$Legend[i] <- 'False'
    }
  } 
  ct$Proportion <- round(ct$Proportion,digits = 3)*100
  
  for (i in as.numeric(row.names(ct[ct$Exp =='total' | ct$Pred =='total', ]))) {
    if (ct$Pred[i]=='total' & ct$Exp[i]!='total') {
      ct$Proportion[i] <- (ct$Freq[i]/ct$Freq[ct$Exp == 'total' & ct$Pred == 'total'])*100
      ct$Legend[i] <- 'Size'
    }
    if (ct$Pred[i]!='total' & ct$Exp[i]=='total') {
      ct$Proportion[[i]] <- (ct$Freq[ct$Exp == ct$Pred[i] & ct$Pred == ct$Pred[i]]/ct$Freq[i])*100
      ct$Legend[i] <- 'Precision'
    }
    if (ct$Pred[i]=='total' & ct$Exp[i]=='total') {
      ct$Proportion[[i]] <- (sum(diag(class.table))/ct$Freq[i])*100
      ct$Legend[i] <- 'Accuracy'
    }
  } 
  ct$Proportion <- round(ct$Proportion,digits = 1)
  
  ct <- mutate(ct,value=ct$Proportion)
  
  for (i in 1:nrow(ct)) {
    if (ct$Legend[i]!='True' & ct$Legend[i]!='False') {
      ct$Proportion[i] <- 45
    }
  }
  
  ct[is.na(ct)] <- 0
  
  base <- ggplot(data = ct, 
                 mapping = aes(x =ordered(Pred, levels =sort(unique(Pred))),
                               y=ordered(Exp, levels =rev(sort(unique(Exp)))),
                               fill = Legend,
                               alpha = Proportion))+
    geom_tile(color = 'black',size = 1.5)+
    coord_fixed()+
    geom_text(aes(label=paste(Freq,"\n",
                              '(',value,'%',')',sep = '')),
              size=4,vjust = .5, fontface  = "bold", alpha = 1)+
    scale_fill_manual(values = c(True = '#6CAE75', False = '#8A0526',
                                 Size = '#FCDEBE', Precision = '#DCAB6B',
                                 Accuracy = '#247BA0'))+
    theme(axis.line = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          axis.text.x = element_text(size = 9,face = 'bold'),
          axis.text.y = element_text(size = 9,face = 'bold'),
          axis.title.y = element_blank(),
          axis.title.x = element_blank(),
          axis.ticks = element_blank())
  
  true.recall <- data.frame(ct$Proportion[ct$Exp == ct$Pred & ct$Exp != 'total'])
  row.names(true.recall) <- unique(as.character(ct$Exp[ct$Exp != 'total']))
  names(true.recall) <- 'Class Recall'
  Low.Recall <<- true.recall
  base + labs(title = plot.title,
              subtitle = 'Confusion Matrix',
              caption = conformation)
}

# prob.heatmap description:
# 
# Takes a nnet::multinom model object.
# Represents the final probabilities table as a heat map with a color gradient based
# on probability percentage. The correctly predicted case names are colored green,
# wrong but second in percentage are colored orange and absolute wrong is colored red.
# The experimental outcome is presented in its own column, color coded for convenience.

prob.heatmap <- function(model, data, plot.title, conformation) {
  pred <- predict(model,newdata = data, 'class')
  r.w <- as.character(pred) == as.character(data$class)
  probs <- round(signif(predict(model,newdata = data, 'probs')*100, 4))
  verif <- data.frame(cbind(as.numeric(as.character(data$class)), pred, r.w, probs, 
                            rep(NA, nrow(probs))))
  row.names(verif) <- row.names(probs)
  
  for (i in 1:dim(verif)[1]) {
    if (verif$r.w[i] == 1) { 
      verif$V7[i] <- "#66a182" # green
    } else {
      if (verif[i,verif[i,1]+3] == min(verif[i,4:6])) {
        verif$V7[i] <- '#d1495b'
      } else {
        if (is.na(verif$V7[i])) {
          verif$V7[i] <-  'tan1'
        }
      }
    }
  }
  
  pro.df <- data.frame(probs)
  pro.df <- rownames_to_column(pro.df)
  pro.df[,1] <- factor(pro.df[,1],levels = pro.df[,1])
  pro.df[,5] <- as.numeric(as.character(data$class))
  colnames(pro.df) <- c('Name',"A","B","C",'Exp')
  row.names(pro.df) <- row.names(probs)
  
  long <- melt(pro.df,id.vars = 'Name')
  long[,3] <- round(long[,3],digits = 2)
  long <- mutate(long, exp_shape=rep(NA,nrow(long)))
  
  
  for (i in 1:nrow(long)) {
    if (long$variable[i] == 'Exp' & long$value[i] == 1) {
      long$exp_shape[i] <- "A"
    }
    if (long$variable[i] == 'Exp' & long$value[i] == 2) {
      long$exp_shape[i] <- 'B'
    }
    if (long$variable[i] == 'Exp' & long$value[i] == 3) {
      long$exp_shape[i] <- 'C'
    }
  }
  shape_vec <- long[long$variable == 'Exp',4]
  col_vec <- shape_vec
  
  for (i in 1:length(col_vec)) {
    if (col_vec[i] == "A") {
      col_vec[i] <- 'darkorchid'
    }
    if (col_vec[i] == 'B') {
      col_vec[i] <- "darkslategray"
    }
    if (col_vec[i] == 'C') {
      col_vec[i] <- "darkgoldenrod4"
    }
    if (col_vec[i] == 'D') {
      col_vec[i] <- "steelblue"
    }
  }
  
  
  
  prob.heatmap <- ggplot(mapping = aes(x = variable,
                                       y =ordered(Name, 
                                                  levels =rev(factor(pro.df$Name, 
                                                                     levels = pro.df$Name)))))+
    geom_tile(data = long[long$variable != 'Exp',], 
              color = 'black',aes(fill = value))+
    coord_fixed(ratio = 0.2)+
    geom_text(data = long[long$variable != 'Exp',], 
              aes(label=value))+
    scale_fill_gradient(name = "% probability",
                        low = "#FFFFFF",
                        high = "dodgerblue3",
                        guide = guide_colorbar(frame.colour = "black", 
                                               ticks.colour = "black"))+
    theme(axis.text.x = element_text(size = 9, face = 'bold',),
          axis.text.y = element_text(size = 9, face = 'bold', 
                                     colour = rev(verif$V7)),
          axis.title.y = element_blank(),
          axis.title.x = element_blank(),
          axis.line = element_blank(),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(),
          panel.background = element_blank(),
          axis.ticks = element_blank())+
    scale_x_discrete(position = "top",limits = levels(long$variable))+
    geom_tile(data = long[long$variable == 'Exp',],
              alpha = 0,inherit.aes = F,
              aes(x=rev(variable),
                  y=ordered(Name, levels =rev(factor(pro.df$Name, 
                                                         levels = pro.df$Name)))))+
    geom_text(data = long[long$variable == 'Exp',], label = shape_vec,
              size = 2.4, color = col_vec, fontface = 'bold')
  
  prob.heatmap + labs(title = plot.title,
              subtitle = 'Probability Heatmap',
              caption = conformation)
}

# simi.sampler description:
#
# Takes data and class as input, yields a subset of the class based
# on a cosine similarity test of the class samples with the class mean vector. 
# This tests how "similar" each sample is to the class itself. 
# The sampler takes the smallest class as the size of subset and measures the 
# the distances of all samples in the class with "poles" stationed in equal spacing 
# from the most similar to the least. 

simi.sampler <- function(data, class, compare.with = 0, plot = F, sample.size = min(summary(as.factor(data$class)))) {
  out.col <- which(colnames(data) == 'class')
  vars <- names(data[,-out.col])
  vars <- vars[vars != 'flag']
  vars <- vars[vars != 'tag']
  sampler.data <- data[vars]
  sampler.data <- data.frame(apply(sampler.data, 2, as.numeric))
  sampler.data <- data.frame(scale(sampler.data, T, T))
  var.nums <- 1:dim(sampler.data)[2]
  classes <- length(unique(data$class))
  
  # compute mean values vector for each of the groups - for similarity
  for (i in 1:classes) {
    assign(paste('class.', as.character(i), '.vector', sep = ''), 
           apply(sampler.data[data$class == i,][,vars], 2, mean))
    assign(paste('class.', as.character(i), '.mag', sep = ''), 
           sqrt(sum(apply(sampler.data[data$class == i,][,vars], 2, mean)^2)))
  }
  
  # compute similarity of each group with itself - same class
  new.col <- dim(sampler.data)[2] + 1
  for (r in 1:nrow(sampler.data)) {
    for (i in 1:classes) {
      if (data$class[r] == i) {
        vec <- get(ls()[which(grepl(paste('.',as.character(i),'.vector',sep = ''), ls()))])
        mag <- get(ls()[which(grepl(paste('.',as.character(i),'.mag',sep = ''), ls()))]) 
        sampler.data[r ,new.col] <- sum(vec*sampler.data[r, 1:(new.col - 1)])/((mag*sqrt(sum(sampler.data[r, 1:(new.col - 1)]^2))))
      }
    }
  }
  
  # compute similarity between classes
  simi.df <- data.frame(matrix(ncol = classes, nrow = nrow(data)))
  for (i in 1:nrow(simi.df)) {
    for (j in 1:classes) {
      vec <- get(ls()[which(grepl(paste('.',as.character(j),'.vector',sep = ''), ls()))])
      mag <- get(ls()[which(grepl(paste('.',as.character(j),'.mag',sep = ''), ls()))]) 
      simi.df[i ,j] <- sum(vec*sampler.data[i, 1:(new.col - 1)])/((mag*sqrt(sum(sampler.data[i, 1:(new.col - 1)]^2))))
    }
  }
  names(simi.df) <- as.character(seq(1, classes))
  
  names(sampler.data)[new.col] <- 'class.similarity'
  simi.table <- cbind(sampler.data[new.col], simi.df)
  simi.table <- dplyr::mutate(simi.table, data$class)
  simi.table <- dplyr::mutate(simi.table, row.names(data))
  simi.table <- dplyr::mutate(simi.table, data$flag)
  colnames(simi.table)[c(1, (2 + classes):dim(simi.table)[2])] <- c('same.class','class','Name', 'flag')
  
  
  plot.sim.before <- ggplot(simi.table, aes(simi.table[,compare.with + 1], y = class, label = Name)) +
    geom_point(aes(color = class)) +
    geom_text_repel(aes(label = Name), max.overlaps = 25) +
    theme(axis.line.x = element_line(size = 1, colour = "black"),
          axis.line.y = element_line(size = 1, colour = "black"),
          axis.text.x = element_text(colour = "black", size = 12,face = 'bold'),
          axis.text.y = element_text(colour = "black", size = 12,face = 'bold'),
          axis.title.x = element_text(colour = "black", size = 12,face = 'bold'),
          axis.title.y = element_text(colour = "black", size = 12,face = 'bold'),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(), panel.background = element_blank(),
          legend.position = c(2,2)) +
    xlab(names(simi.table)[compare.with + 1]) + 
    ggtitle('Similarity Before Group Truncation')
  
  
  
  #sample.size <-  min(summary(as.factor(data$class)))
  simi.class <- simi.table[simi.table$class == class, compare.with + 1]
  steps <-  sort(seq(min(simi.class), max(simi.class), (max(simi.class) - min(simi.class))/(sample.size - 1)))
  dis.mat <- matrix(ncol = length(steps), nrow = length(sort(simi.class)))
  for (i in 1:nrow(dis.mat)) {
    dis.mat[i, ] <- abs(simi.class[i] - steps)
  }
  pts <- vector()
  row.names(dis.mat) <- as.character(simi.table$flag[simi.table$class == class])
  if (length(steps) < length(simi.class)) {
    for (i in 1:ncol(dis.mat)) {
      drop <- which.min(dis.mat[, i])
      pts[i] <- simi.table[as.numeric(names(drop)), 1]
      dis.mat <- dis.mat[-drop, ]
    }
  } else {
    pts <- simi.table[as.numeric(row.names(dis.mat)), 1]
  }
  keep <- as.numeric(simi.table$flag[simi.table$same.class %in% pts])
  
  class.rows <- simi.table$flag[simi.table$class == class]
  if (min(class.rows) != 1) {
    truncated <- unique(c(1:(min(class.rows) + 1), keep, (max(class.rows) + 1):nrow(data)))
  } else {
    truncated <- unique(c(keep, (max(class.rows) + 1):nrow(data)))
  }
  simi.plot.data <- simi.table[truncated,][complete.cases(simi.table[truncated,]),]
  plot.sim.after <- ggplot(simi.plot.data,
                           aes(x = simi.plot.data[, compare.with + 1],
                               y = class, label = Name)) +
    geom_point(aes(color = class)) +
    geom_text_repel(aes(label = Name), max.overlaps = 25) +
    theme(axis.line.x = element_line(size = 1, colour = "black"),
          axis.line.y = element_line(size = 1, colour = "black"),
          axis.text.x = element_text(colour = "black", size = 12,face = 'bold'),
          axis.text.y = element_text(colour = "black", size = 12,face = 'bold'),
          axis.title.x = element_text(colour = "black", size = 12,face = 'bold'),
          axis.title.y = element_text(colour = "black", size = 12,face = 'bold'),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.border = element_blank(), panel.background = element_blank(),
          legend.position = c(2,2)) +
    xlab(names(simi.table)[compare.with + 1]) + 
    ggtitle('Similarity After Group Truncation')
  
  if (isTRUE(plot)) gridExtra::grid.arrange(plot.sim.before, plot.sim.after, ncol = 2)
  
  return(keep)
}
```

### Model Search

``` {r Model Search}
data <- data.frame(data.table::fread('LEC_Data.csv'), check.names = F) # Import data

row.names(data) <- data[,2]
data$class <- as.factor(data$class)
kfold.data <- data[,-c(1:2)] # Remove name and tag

one <- simi.sampler(kfold.data, 1)
two <- simi.sampler(kfold.data, 2)
three <- simi.sampler(kfold.data, 3)
one_three <- simi.sampler(kfold.data, 1, 3)
two_three <- simi.sampler(kfold.data, 2, 3)


uni_similarties <- c(union(one, one_three),
                     union(two, two_three),
                     three)

# models <- sub_model_log_McFadden(data = kfold.data[uni_similarties, ],
#                                                min = 4,
#                                                max = 4)
  
models <- data.frame(data.table::fread('4_features_models_nonordinal.csv'))[, -1]
 
knitr::kable(models) # present list of models
#write.csv(models, '4_features_models_nonordinal.csv')

test.data <- kfold.data[uni_similarties, ]
Test.set <- kfold.data[-uni_similarties, ]


Predictions_data <- data.frame(data.table::fread('LEC_External_Data.csv'))
RN <- Predictions_data$V1
Predictions_data <- Predictions_data[,-1]
Predictions_data$class <- as.factor(Predictions_data$class)
row.names(Predictions_data) <- RN
```


### 1st Place
``` {r 1.1}
test.form <- models[1, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '1. 1st Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '1. 1st Place')
```

```{r 1.2}

                                                                  
mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '1. 1st Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '1. 1st Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.1 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.1) <- '1. 1st Place'
```

```{r 1.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '1. 1st Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '1. 1st Place')
```

### 2nd Place
``` {r 2.1}
test.form <- models[2, 1]


test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '2. 2nd Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '2. 2nd Place')
```

```{r 2.2}

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '2. 2nd Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '2. 2nd Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.2 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.2) <- '2. 2nd Place'
```

```{r 2.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '2. 2nd Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '2. 2nd Place')
```

### 3rd Place
``` {r 3.1}
test.form <- models[3, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '3. 3rd Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '3. 3rd Place')
```

```{r 3.2}

                                                                  
                                                                  
                                                                  

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '3. 3rd Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '3. 3rd Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.3 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.3) <- '3. 3rd Place'
```

```{r 3.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '3. 3rd Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '3. 3rd Place')
```

### 4th Place
``` {r 4.1}
test.form <- models[4, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '4. 4th Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '4. 4th Place')
```

```{r 4.2}

                                                                  
                                                                  
                                                                  

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '4. 4th Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '4. 4th Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.4 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.4) <- '4. 4th Place'
```

```{r 4.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '4. 4th Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '4. 4th Place')
```

### 5th Place
``` {r 5.1}
test.form <- models[5, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '5. 5th Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '5. 5th Place')
```

```{r 5.2}

                                                                  
                                                                  
                                                                  

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '5. 5th Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '5. 5th Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.5 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.5) <- '5. 5th Place'
```

```{r 5.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '5. 5th Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '5. 5th Place')
```

### 6th Place
``` {r 6.1}
test.form <- models[6, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '6. 6th Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '6. 6th Place')
```

```{r 6.2}

                                                                  
                                                                  
                                                                  

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '6. 6th Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '6. 6th Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.6 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.6) <- '6. 6th Place'
```

```{r 6.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '6. 6th Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '6. 6th Place')
```

### 7th Place
``` {r 7.1}
test.form <- models[7, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '7. 7th Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '7. 7th Place')
```

```{r 7.2}

                                                                  
                                                                  
                                                                  

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '7. 7th Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '7. 7th Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.7 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.7) <- '7. 7th Place'
```

```{r 7.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '7. 7th Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '7. 7th Place')
```

### 8th Place
``` {r 8.1}
test.form <- models[8, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '8. 8th Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '8. 8th Place')
```

```{r 8.2}

                                                                  
                                                                  
                                                                  

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '8. 8th Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '8. 8th Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.8 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.8) <- '8. 8th Place'
```

```{r 8.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '8. 8th Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '8. 8th Place')
```

### 9th Place
``` {r 9.1}
test.form <- models[9, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '9. 9th Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '9. 9th Place')
```

```{r 9.2}

                                                                  
                                                                  
                                                                  

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '9. 9th Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '9. 9th Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.9 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.9) <- '9. 9th Place'
```

```{r 9.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '9. 9th Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '9. 9th Place')
```

### 10th Place
``` {r 10.1}
test.form <- models[10, 1]

test <- nnet::multinom(test.form,
                       data = test.data,
                       maxit = 2000, 
                       trace = F)
                   

mod.info(test, test.data, T, T)

ct.plot(class.table, 
        plot.title = 'Training Set',
        conformation = '10. 10th Place')

prob.heatmap(test, test.data, 
        plot.title = 'Training Set',
        conformation = '10. 10th Place')
```

```{r 10.2}

                                                                  
                                                                  
                                                                  

mod.info(test, Test.set, F, F)

ct.plot(class.table, 
        plot.title = 'Test Set',
        conformation = '10. 10th Place')

prob.heatmap(test, Test.set, 
        plot.title = 'Test Set',
        conformation = '10. 10th Place')

percentage <- round((sum(diag(table(predict(test, Test.set), Test.set$class))) / nrow(Test.set)) * 100, 1)
model.sum.10 <- data.frame('Training Accuracy' = Acc.print, 'Test Accuracy' = percentage)
row.names(model.sum.10) <- '10. 10th Place'
```

```{r 10.3}

mod.info(test, Predictions_data, F)

ct.plot(class.table, 
        plot.title = 'External Validation',
        conformation = '10. 10th Place')

prob.heatmap(test, Predictions_data, 
        plot.title = 'External Validation',
        conformation = '10. 10th Place')
```

### Section Results Summary
```{r sum 1}
knitr::kable(rbind(model.sum.1, model.sum.2, model.sum.3, model.sum.4, 
                   model.sum.5, model.sum.6, model.sum.7, model.sum.8,
                   model.sum.9, model.sum.10))
```


